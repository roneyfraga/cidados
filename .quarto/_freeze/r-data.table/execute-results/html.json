{
  "hash": "a4e2e55408163ec2fb321db0af33b1f8",
  "result": {
    "markdown": "\n# Velocidade com `data.table`\n\n- data.table\n\n\n::: {.cell filename='r-05.R'}\n\n```{.r .cell-code  code-fold=\"show\"}\n# ------------------------------------------------------------\n# \n# File Name: CiDados_aula05.R\n#\n# Purpose: Ciência de Dados para Economistas - Faculdade de Economia UFMT\n# \n# Creation Date: 2020-10-30\n# Last Modified: 2022-10-20 \n# Created By: Roney Fraga Souza\n# E-mail: roneyfraga@gmail.com\n# roneyfraga.com\n# \n# Licence:\n#\n# Creative Commons Attribution-NonCommercial-ShareAlike \n# CC BY-NC-SA\n# http://creativecommons.org/licenses/by-nc-sa/3.0/\n#\n# ------------------------------------------------------------\n\n\n# Parte 1: desempenho na importacação e exportação de dados\n# Parte 2: sintax do pacote data.table\n# Parte 3: pacotes dtplyr e tidyfast\n# Parte 4: microdados: bare metal OR blazingly fast _way\n\n\n# ------------------------------\n## Parte 1: desempenho na importacação e exportação de dados\n\nlibrary(tidyverse) \nlibrary(rio)\nlibrary(data.table) \nlibrary(tictoc)\n\n\n# Configuração do meu computador\n# OS: Manjaro 21.2.5 Qonos\n# CPU: AMD Ryzen 9 5900X 12-Core @ 24x 3.7GHz\n# GPU: AMD/ATI Ellesmere [Radeon RX 570]\n# RAM: 128 GB \n# SSD1: 480 GB for Operacional System \n# SSD2: raid0 2 TB for Data\n\n\n# --- import\n\n# importação dos dados do censo demográfico (csv e rds)\n# https://www.ibge.gov.br/estatisticas/sociais/populacao/9662-censo-demografico-2010.html?=&t=microdados\nbr2010_csv <- '/mnt/raid0/Pesquisa/Censo 2010/Brasil/br2010.csv' # 12 GB\nbr2010_rds <- '/mnt/raid0/Pesquisa/Censo 2010/Brasil/br2010.rds' # 950 MB\n\ntictoc::tic()\nbr2010 <- data.table::fread(br2010_csv)\ntictoc::toc()\n# 5.101 sec\n\ntictoc::tic()\nbr2010b <- rio::import(br2010_rds)\ntictoc::toc()\n# 52.156 sec\n\ntictoc::tic()\nbr2010c <- read_csv(br2010_csv)\ntictoc::toc()\n# R travou e fechou  \n\n# --- export\ntictoc::tic()\ndata.table::fwrite(br2010, '~/br2010.csv')\ntictoc::toc()\n# 7.899 sec\n\ntictoc::tic()\nrio::export(br2010b, '~/br2010.rds')\ntictoc::toc()\n# 321.775 sec | 5.36 min\n\ntictoc::tic()\nwrite_csv(br2010b, '~/br2010_baser.csv')\ntictoc::toc()\n# 27 sec \n\n# ---  \n# conclusão: caminho mais rápido para importar exportar dados é o data.table\n#\n# salvar um csv no data.table::fwrite() é 46 vezes mais rápido que um saveRDS() nativo do R\n# salvar um csv no data.table::fwrite() é ~= 4 vezes mais rápido que um write_csv() nativo do R\n#\n# ler um csv com data.table::fread() é ~= 10 vezes mais rápido que um readRDS() nativo do R\n# o R travou tentando ler o csv com read_csv() \n# --- \n\n\n\n\n# ------------------------------\n## Parte 2: pacote data.table\n\nlibrary(data.table)\n\n# ---------------------\n# full performance benchmarking\n# https://h2oai.github.io/db-benchmark/\n\n# resume benchmarking\n# https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/\n\n# comporando: dplyr | data.table | pandas | DataFrames.jl | Arrow | Spark | Polars | etc\n\n# ---------------------\n# see oficial page\n# https://rdatatable.gitlab.io/data.table/\n\nDT <- data.table::as.data.table(iris)\n\n# DT[ i,  j,  by ] # + extra arguments\n#     |   |   |\n#     |   |    -------> grouped by what?\n#     |    -------> what to do?\n#      ---> on which rows?\n\nDT[Petal.Width > 1.0, mean(Petal.Length), by = Species]\nDT[Petal.Width > 1.0, mean(Petal.Length)]\n\n\n# ---------------------\n# tutorial básico\n# https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html\n\ninput <- if (file.exists(\"flights14.csv\")) {\n    \"flights14.csv\"\n} else {\n    \"https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv\"\n}\n\nflights <- data.table::fread(input) \nclass(flights)\ndim(flights)\n\n# Get all the flights with “JFK” as the origin airport in the month of June\nans <- flights[origin == \"JFK\" & month == 6L]\nhead(ans)\n\n# %chin% special operator, similar to %in% but faster \nans <- flights[carrier %chin% c('AA', 'AS', 'B6')]\nhead(ans)\n\n# Get the first two rows from flights.\nans <- flights[1:2]\nans\n\n# Sort flights first by column origin in ascending order, and then by dest in descending order:\nans <- flights[order(origin, -dest)]\nhead(ans)\n\n# Select arr_delay column, but return it as a vector.\nans <- flights[, arr_delay]\nhead(ans)\n\n# Select column and return DT: caminho 1\nans <- flights[, list(arr_delay)]\nhead(ans)\n\n# Select column and return DT: caminho 2\nans <- flights[, .(arr_delay, dep_delay)]\nhead(ans)\n\n# Select column and return DT: caminho 3\nans <- flights[, c('arr_delay', 'dep_delay')]\nhead(ans)\n\n# Select column and return DT: caminho 4\n# .. operator, global\nselect_cols <- c(\"arr_delay\", \"dep_delay\")\nflights[, ..select_cols]\n\n# Select columns named in a variable using with = FALSE\nflights[, select_cols, with = FALSE] \n\n# Select both arr_delay and dep_delay columns and rename them to delay_arr and delay_dep.\nans <- flights[, .(delay_arr = arr_delay, delay_dep = dep_delay)]\nhead(ans) \n\n# How many trips have had total delay < 0?\nans <- flights[, sum((arr_delay + dep_delay) < 0)]\nans\n\n# Calculate the average arrival and departure delay for all flights with “JFK” as the origin airport in the month of June.\nans <- flights[origin == \"JFK\" & month == 6L, \n               .(m_arr = mean(arr_delay), \n                 m_dep = mean(dep_delay))]\nans\n\n# How many trips have been made in 2014 from “JFK” airport in the month of June?\nans <- flights[origin == \"JFK\" & month == 6L, length(dest)]\nans\n\n# Special symbol .N:\n# .N is a special built-in variable that holds the number of observations in the current group. It is particularly useful when combined with by as we’ll see in the next section. In the absence of group by operations, it simply returns the number of rows in the subset.\nans <- flights[origin == \"JFK\" & month == 6L, .N]\nans\n\n# Agregations\nans <- flights[, .(.N), by = .(origin)]\nans\n\n# How can we calculate the number of trips for each origin airport for carrier code \"AA\"\nans <- flights[carrier == \"AA\", .N, by = origin]\nans\n\n# How can we get the total number of trips for each origin, dest pair for carrier code \"AA\"?\nans <- flights[carrier == \"AA\", .N, by = .(origin, dest)]\nhead(ans)\n\n# and order\nflights[carrier == \"AA\", .N, by = .(origin, dest)][order(-N)]\n\n# So how can we directly order by all the grouping variables?\nans <- flights[carrier == \"AA\", \n               .(mean(arr_delay), mean(dep_delay)), \n               keyby = .(origin, dest, month)]\nans\n\n# order\nans[order(V1, V2)]\n\n# Can by accept expressions as well or does it just take columns?\n# Yes it does. As an example, if we would like to find out how many flights started late but arrived early (or on time), started and arrived late etc…\nans <- flights[, .N, .(dep_delay > 0, arr_delay > 0)]\nans\n\n# Special symbol .SD:\n# data.table provides a special symbol, called .SD. It stands for Subset of Data. \nDT\nDT[, print(.SD), by = Species]\n\n# .SDcols\nflights[carrier == \"AA\",                       ## Only on trips with carrier \"AA\"\n        lapply(.SD, mean),                     ## compute the mean\n        by = .(origin, dest, month),           ## for every 'origin,dest,month'\n        .SDcols = c(\"arr_delay\", \"dep_delay\")] ## for just those specified in .SDcols\n\n# How can we return the first two rows for each month?\nans <- flights[, head(.SD, 2), by = month]\nhead(ans)\n\n# :=\n# walrus operator, atribuição dentro de um DT\nflights[, atrasou := ifelse(arr_delay > 10, 'Sim', 'Não')]\nflights[, teste := 'testando']\nflights\n\n# deletar variável\nflights[, - c('teste', 'atrasou')]\nflights[, teste := NULL]\nflights[, atrasou := NULL]\nflights\n\n\n# ------------------------------\n## Parte 3: pacotes dtplyr e tidyfast\n\n# sintax do dplyr com objetos data.table\n\n# data.table vs dplyr\n# https://atrebas.github.io/post/2019-03-03-datatable-dplyr/\n\n# material oficial\n# https://dtplyr.tidyverse.org/\n\n# tidyfast\n# https://tysonbarrett.com/tidyfast/\n\n# tradutor dplyr sintax para data.table sintax\nlibrary(tidyverse) \nlibrary(dtplyr)          # dplyr equivalente  \nlibrary(tidyfast)        # tidyr equivalente (também existe tidytable)\nlibrary(rio) \nlibrary(data.table) \nlibrary(microbenchmark) \nlibrary(bench)\nlibrary(tictoc) \n\ndf <- data.frame(a = 1:5, b = 1:5, c = 1:5, d = 1:5)\ndt <- dtplyr::lazy_dt(df)\n\ndt\ndt |> dplyr::show_query()\ndt |> dplyr::select(a:b) |> dplyr::show_query()\ndt |> dplyr::select(a:b) \ndt |> dplyr::select(a:b) |> tibble::as_tibble() \n\ndt |> dplyr::select(a:b) |> dplyr::filter(a <= 3) |> dplyr::arrange(desc(b)) \ndt |> dplyr::select(a:b) |> dplyr::filter(a <= 3) |> dplyr::arrange(desc(b)) |> dplyr::show_query()\n\ndt |> dplyr::arrange(a, b, c)\ndt |> dplyr::select(a:b)\ndt |> dplyr::summarise(a = mean(a)) \ndt |> dplyr::transmute(a2 = a * 2) \ndt |> dplyr::mutate(a2 = a * 2, b2 = b * 2)\ndt |> dplyr::mutate(a2 = a * 2, b2 = b * 2, a4 = a2 * 2)\ndt |> dplyr::transmute(a2 = a * 2, b2 = b * 2, a4 = a2 * 2)\ndt |> dplyr::rename(x = a, y = b)\ndt |> dplyr::distinct() \ndt |> dplyr::distinct(a, b) \ndt |> dplyr::distinct(a, b, .keep_all = TRUE) \ndt |> dplyr::distinct(c = a + b) \ndt |> dplyr::distinct(c = a + b, .keep_all = TRUE) \n\ndt2 <- dtplyr::lazy_dt(data.frame(a = 1))\ndt |> dplyr::inner_join(dt2, by = \"a\") \ndt |> dplyr::right_join(dt2, by = \"a\")\ndt |> dplyr::left_join(dt2, by = \"a\")\ndt |> dplyr::anti_join(dt2, by = \"a\")\ndt |> dplyr::full_join(dt2, by = \"a\") \ndt |> dplyr::full_join(dt2, by = \"a\") |> dplyr::show_query()\n\ndt |> dplyr::group_by(a) |> dplyr::summarise(b = mean(b))\ndt |> dplyr::group_by(a, arrange = FALSE) |> dplyr::summarise(b = mean(b))\ndt |> dplyr::group_by(a) |> dplyr::filter(b < mean(b))\n\ndt |> dplyr::filter(a == 1) |> dplyr::select(-a)\n\ndt3 <- dtplyr::lazy_dt(data.frame(x = 1, y = 2))\ndt4 <- dtplyr::lazy_dt(data.frame(x = 1, a = 2, b = 3, c = 4, d = 5, e = 7))\n\ndt3 |> \n  dplyr::left_join(dt4) |> \n  dplyr::select(x, a:c) \n\ndt |> dplyr::mutate(a2 = a * 2, b2 = b * 2) \n\n# ----------\n# benchmark lattes dados gerais\n\n# data.frame\ndg_original <- data.table::fread('/mnt/raid0/Pesquisa/lattes_2020/lattes_tables/DadosGerais.csv') \ndg_original\ndim(dg_original)\n\n# data.frame\ndg_df <- dg_original[1:1000000, ] |> as.data.frame() \n\n# tibble\ndg_tb <- tibble::as_tibble(dg_df) \n\n# data.table dtplyr\ndg_lazy_dt <- dtplyr::lazy_dt(dg_df)\n\n# data.table original\ndg_dt <- data.table::as.data.table(dg_df)\n\n# select and arrange\nmicrobenchmark::microbenchmark(\n    data_frame = dg_df[order(dg_df$nome_completo), c('nome_completo', 'pais_de_nascimento', 'data_atualizacao', 'id')], \n    data_tibble = dg_tb |> dplyr::select(nome_completo, pais_de_nascimento, data_atualizacao, id) |> dplyr::arrange(nome_completo),  \n    data_table_lazy_dt = dg_lazy_dt |> dplyr::select(nome_completo, pais_de_nascimento, data_atualizacao, id) |> dplyr::arrange(nome_completo),\n    data_table_orig = dg_dt[, .(nome_completo, pais_de_nascimento, data_atualizacao, id)][order(nome_completo)],\n    times = 2 \n)\n\n# Unit: milliseconds\n#                expr          min           lq         mean       median           uq          max neval cld\n#          data_frame 15942.813793 15942.813793 16187.456176 16187.456176 16432.098559 16432.098559     2  b \n#         data_tibble 17886.188947 17886.188947 18185.199119 18185.199119 18484.209291 18484.209291     2   c\n#  data_table_lazy_dt     2.583712     2.583712     3.424582     3.424582     4.265453     4.265453     2 a  \n#     data_table_orig   930.093906   930.093906   932.617333   932.617333   935.140760   935.140760     2 a  \n\n\n# ----------\n# data.table import text files\n\n# olhar para os dados, primeiras 10 linhas \na <- data.table::fread('flights14.csv', nrows = 10)\na\n\n# selecionar colunas ao importar\ndata.table::fread('flights14.csv', select = c('year', 'month', 'day', 'distance', 'carrier'))\n\n# excluir colunas\ndata.table::fread('flights14.csv', drop = c(4, 6))\n\n# filter com grep nativo do Linux \ndata.table::fread('grep AA flights14.csv')\n\n# filter com nomes das colunas\ndata.table::fread('grep AA flights14.csv', col.names = names(a))\n\n# filter AE e DL\ndata.table::fread(\"grep ⁻E 'AA|DL' flights14.csv\", col.names = names(a))\n\n# %in% but faster\ndt <- data.table::fread('flights14.csv')\ndt[carrier %chin% c('AE', 'DL')]\n\n# classe das colunas\ndata.table::fread('flights14.csv', \n                  colClasses = c(year = \"character\", \n                                 month = \"character\", \n                                 day = \"character\")) |> \n    dplyr::glimpse()\n\n# ler zip sem unzip\ndata.table::fread(cmd = 'unzip -cq flights14.zip') \n\n# ler arquivo e depois transormar com setDT\ndf <- data.table::setDT(readxl::read_excel('flights14.xlsx'))\n\n# ou\ndf <- readxl::read_excel('flights14.xlsx')\n\ndata.table::setDT(df)\n\ndt <- dtplyr::lazy_dt(df) \n\n# threads\ngetDTthreads(verbose = TRUE)\n\n# ----------\n# tidyfast\n\n#Tidy data is data where:\n#\n#     Every column is variable.\n#     Every row is an observation.\n#     Every cell is a single value.\n\n\ndt <- data.table(\n   x = rnorm(1e5),\n   y = runif(1e5),\n   grp = sample(1L:5L, 1e5, replace = TRUE),\n   nested1 = lapply(1:10, sample, 10, replace = TRUE),\n   nested2 = lapply(c(\"thing1\", \"thing2\"), sample, 10, replace = TRUE),\n   id = 1:1e5)\n\ndt\n\nnested <- tidyfast::dt_nest(dt, grp)\nnested\n\n# Nesting and Unnesting\ntidyfast::dt_unnest(nested, col = data)\ntidyfast::dt_hoist(dt, nested1, nested2)\n\n# Pivoting\nbillboard <- tidyr::billboard\n\nbillboard |>\n    tidyfast::dt_pivot_longer(cols = c(-artist, -track, -date.entered), \n                              names_to = \"week\", values_to = \"rank\") ->\n    longer\n\nlonger |> \n    tidyfast::dt_pivot_wider(names_from = week, values_from = rank) ->\n    wider\n\nwider[, .(artist, track, wk1, wk2)]\n\n# If Else\nx <- rnorm(1e6)\n\nmedianx <- median(x)\n\ntidyfast::dt_case_when(x < medianx ~ \"low\", \n                       x >= medianx ~ \"high\", \n                       is.na(x) ~ \"unknown\") ->\n    x_cat\n\ndplyr::case_when(x < medianx ~ \"low\", \n                 x >= medianx ~ \"high\", \n                 is.na(x) ~ \"unknown\") ->\nx_cat_dplyr \n\ndata.table::fifelse(x < medianx, \"low\", \n                    data.table::fifelse(x >= medianx, \"high\", \n                                        data.table::fifelse(is.na(x), \"unknown\", NA_character_))) ->\n    x_cat_fif\n\nidentical(x_cat, x_cat_dplyr)\nidentical(x_cat, x_cat_fif)\n\n# Fill\nx <- 1:10\n\ndata.table(x = x, y = shift(x, 2L), \n           z = shift(x, -2L), \n           a = sample(c(rep(NA, 10), x), 10), \n           id = sample(1:3, 10, replace = TRUE)) ->\n    dt_with_nas\n\ntidyfast::dt_fill(dt_with_nas, y, z, a)\ntidyfast::dt_fill(dt_with_nas, y, z, a, id = list(id))\ntidyfast::dt_fill(dt_with_nas, y, z, a, id = list(id), .direction = \"downup\")\n\nx <- 1:1e6\n\ndata.table(x = x, y = shift(x, 10L), \n           z = shift(x, -10L), \n           a = sample(c(rep(NA, 10), x), 10), \n           id = sample(1:3, 10, replace = TRUE)) -> \n    dt3 \ndf3 <- data.frame(dt3)\n\nbench::mark(tidyr::fill(dplyr::group_by(df3, id), x, y), \n            tidyfast::dt_fill(dt3, x, y, id = list(id)), \n            check = FALSE, \n            iterations = 50) ->\n    marks3 \n\n# Separate\n# The dt_separate() function is still under heavy development\n\n# Count and Uncount\ncounted <- tidyfast::dt_count(dt, grp)\ncounted\n\nuncounted <- tidyfast::dt_uncount(counted, N)\nuncounted[]\n\n\n\n# ------------------------------\n# Parte 4: microdados: bare metal OR blazingly fast _way\n\nlibrary(tidyverse) \nlibrary(dtplyr)          # dplyr equivalente  \nlibrary(tidyfast)        # tidyr equivalente (também existe tidytable)\nlibrary(data.table) \n\n\n# censo da educação superior\nces_curso_csv <- '/mnt/raid0/Pesquisa/microdados_censo_da_educacao_superior_2020/dados/MICRODADOS_CADASTRO_CURSOS_2020.CSV' # 182 MB\nces_ies_csv <- '/mnt/raid0/Pesquisa/microdados_censo_da_educacao_superior_2020/dados/MICRODADOS_CADASTRO_IES_2020.CSV' # 1 MB\n\ndata.table::fread(ces_curso_csv, nrows = 1, select = 1:7)\n\nread.table(ces_curso_csv, header = T, sep = ';', nrows = 1) |>\n    dplyr::select(1:7) \n\n# --- problema de enconding: \n# 'Educação' vira 'Educa\\xe7\\xe3o'\n# 'Água' vira '\\xc1gua'\n\n# descrobrir encode no terminal do linux e macOS\n# > file -i MICRODADOS_CADASTRO_CURSOS_2020.CSV\n\n# rio::import() utiliza o data.table::fread() para ler arquivos csv \ntictoc::tic()\ndata.table::fread(ces_curso_csv, encoding = 'Latin-1') |>\n    janitor::clean_names() |>\n    dtplyr::lazy_dt() -> \n    curso\ntictoc::toc()\n\ndata.table::fread(ces_ies_csv, encoding = 'Latin-1') |>\n    janitor::clean_names() |>\n    dtplyr::lazy_dt() -> \n    ies\n\n# ---\n# solução nativa do R: fileEncoding = 'iso-8859-1'\nread.table(ces_curso_csv, header = T, sep = ';', nrows = 1, fileEncoding = 'iso-8859-1') |>\n    dplyr::select(1:7) \n# ---\n\nclass(curso)\nclass(ies)\n\nies |> dplyr::select(co_ies, no_ies, sg_ies) \n\ncurso |> \n    dplyr::select(nu_ano_censo, no_regiao, no_uf, no_municipio, \n                  in_capital, tp_rede, co_ies, no_cine_rotulo) |>\n    dplyr::filter(no_uf == 'Mato Grosso') \n\n# existe mais de uma linha por curso?\ncurso |> \n    dplyr::filter(no_uf == 'Mato Grosso') |>\n    dplyr::count(co_ies, co_cine_rotulo, sort = T)\n\n# centros de ensino e cursos\ncurso |> \n    dplyr::filter(no_uf == 'Mato Grosso') |>\n    dplyr::select(nu_ano_censo, no_regiao, no_uf, no_municipio, \n                  in_capital, tp_organizacao_academica, tp_categoria_administrativa,\n                  tp_rede, co_ies, co_cine_rotulo, no_cine_rotulo) |>\n    dplyr::left_join(ies |> dplyr::select(co_ies, no_ies, sg_ies)) |>\n    dplyr::count(no_ies, no_cine_rotulo, sort = T) |>\n    dplyr::select(- n) |> \n    dplyr::show_query()\n    tibble::as_tibble() ->\n    t1\n\nt1 |>\n    dplyr::filter(grepl('universidade federal de mato grosso', ignore.case = T, no_ies)) |>\n    print(n = Inf)\n\nt1 |> dplyr::count(no_ies, sort = T) \nt1 |> dplyr::count(no_cine_rotulo, sort = T) \n\n# ---- censo populacional 2010\n#\nbr2010_csv <- '/mnt/raid0/Pesquisa/Censo 2010/Brasil/br2010.csv' # 12 GB\n\ntictoc::tic()\ndata.table::fread(br2010_csv) |> \n    janitor::clean_names() |> \n    dtplyr::lazy_dt() ->\n    br2010\ntictoc::toc()\n\ntictoc::tic()\nbr2010 |> \n    dplyr::group_by(v1001, v0601) |>\n    dplyr::summarise(qtde_pessoas = n()) |>\n    dplyr::rename(regiao = v1001, sexo = v0601) |>\n    tibble::as_tibble() |>\n    print(n = Inf)\ntictoc::toc()\n# 7.54\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}